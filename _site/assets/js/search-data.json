{
  "1": {
    "id": "1",
    "title": "Blog",
    "content": "",
    "url": "http://localhost:4000/just-the-docs/Blog",
    "relUrl": "/Blog"
  },
  "2": {
    "id": "2",
    "title": "Contact",
    "content": "Contact Feel free to reach out to me via email at t@imtiaan.com or via social media.",
    "url": "http://localhost:4000/just-the-docs/Contact",
    "relUrl": "/Contact"
  },
  "3": {
    "id": "3",
    "title": "Code",
    "content": "Code Example Ethereum Tipping &lt;a href=&quot;#&quot; id=&quot;eth_tip_button&quot; onclick=&quot;onEthTipButtonClick();&quot;&gt; // The text on the button üëá ETHER TIP &lt;/a&gt; &lt;script type=&quot;text/javascript&quot;&gt; // Replace 0x36eb9A0F170E99350693e09Fa1f3E894C334451A with your Ethereum address üëá var ETH_ADDRESS = &#39;0x36eb9A0F170E99350693e09Fa1f3E894C334451A&#39;; // Set the donation amount in Ether üëá // In this case 0.01 ETH = around $1.35 var ETH_VALUE = &#39;0.01&#39;; // This is the default gas price - feel free to adjust it if the default changes in the future üëá // Currently this is the standard var ETH_DEFAULT_GAS_PRICE = 21000000000; // Create a confirmation message üëá var ETH_SUCCESS_MESSAGE = &#39;Thank you for your donation of 0.01 ETH! üôå&#39;; // Creat an error message üëá var ETH_ERROR_MESSAGE = &#39;Oh no! ü§¶‚Äç‚ôÇÔ∏è Something went wrong!&#39;; // set a message to show when MetaMask is not available. üëá var ETH_WEB3_UNAVAILABLE_MESSAGE = &#39;Your web3 wallet is unavailable.&#39; To donate, please feel free to send Ether to 0x36eb9A0F170E99350693e09Fa1f3E894C334451A - Thank you!&#39;;&#39; &lt;/script&gt; &lt;style&gt; #eth_tip_button { position: relative; display: inline-block; padding: 0.2em 0.4em; border-radius: 3px; font-weight: 500; text-decoration: none; color: #ffffff; background: #00a968; } &lt;/style&gt; &lt;script src=&quot;https://cdn.jsdelivr.net/gh/ethereum/web3.js@0.20.6/dist/web3.min.js&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot;&gt; function onEthTipButtonClick() { var isWeb3Available = false; if (typeof web3 !== &#39;undefined&#39;) { web3 = new Web3(web3.currentProvider); isWeb3Available = true; } if (isWeb3Available &amp;&amp; web3.eth.defaultAccount) { sendEther(); } else { alert(ETH_WEB3_UNAVAILABLE_MESSAGE); } }; function sendEther() { var weiValue = web3.toWei(ETH_VALUE, &#39;ether&#39;); var transactionObj = { to: ETH_ADDRESS, value: weiValue, gasPrice: ETH_DEFAULT_GAS_PRICE }; web3.eth.sendTransaction(transactionObj, function(error, txHash) { if (error) { alert(ETH_ERROR_MESSAGE); } else { alert(ETH_SUCCESS_MESSAGE); } }); } &lt;/script&gt;",
    "url": "http://localhost:4000/just-the-docs/writing/ETH%20Tipping%20-%20Technical%20Tutorial/",
    "relUrl": "/writing/ETH%20Tipping%20-%20Technical%20Tutorial/"
  },
  "4": {
    "id": "4",
    "title": "Education",
    "content": "Education Having spent 9 years focussing Operations and Marketing in the Oil and Gas Industry, I left the space in 2017 and focussed on building experience in software development and design. This journey started in 2015 with the incorporation of Dev 200 in Cape Town, South Africa with a close friend. The company is still active today and has delivered large scale projects for clients like the World Health Organization. In 2018 I stepped back from the business on a operational level to pursue my interest in cryptocurrencies and blockchain technology. Formal Education Subject Matter Institution Year Web Development University of Cape Town 2016 Project Management University of Cape Town 2016 Digital Marketing University of Cape Town 2016 Digital Currency University of Nicosia 2018 Graphic Design University of Cape Town 2016 Solidity (Ethereum) Udemy 2018 Photography The Photography Institute 2011 Short Courses Subject Matter Institution Year Fundamentals of Digital Marketing Google 2018 Content Promotion Google 2018 Customer Segmentation Google 2018 SEO Google 2019 Basics of Machine Learning Google 2019 Getting Started with Python Google 2019",
    "url": "http://localhost:4000/just-the-docs/Education/",
    "relUrl": "/Education/"
  },
  "5": {
    "id": "5",
    "title": "ImTwitter",
    "content": "incomplete post Chrome Extension Twitter HTML JavaScript ¬†Fork ImTwitter Chrome Extension This project is a Chrome extension that I built to automate a Twitter account from your browser. It is built with features to control the rate of which you perform tasks and has a built in hard limit per session that reduces the likelihood of a twitter soft ban. Features Auto Like Auto Un Like Auto Retweet Auto Un Retweet Auto Follow Auto UnFollow App Scheduling",
    "url": "http://localhost:4000/just-the-docs/ImTwitter",
    "relUrl": "/ImTwitter"
  },
  "6": {
    "id": "6",
    "title": "Whitepaper Extract 3",
    "content": "Whitepaper Extract PROOF OF UTILITY Proof of Utility is a new type of token value calculation method whereby the value of a coin will go up in price for every given number of transactions within a unit of time. We define BT as the Block of Time which is found by taking XN (number of transactions that is set as a threshold) and dividing them by DN (number of days) from the completion of the first transaction to the Xth. The Block of Time unit is a measurement of the robustness and usage of the JetSet ecosystem. It is a key performance indicator by which market forces can act naturally without any manipulation by users, vendors, or JetSet developers. The higher this number becomes the faster XN transactions are being reached. BT =XN /DN Because the transactions will tie back to a real human being behind the JetSet account using AML/KYC verification, the BT calculation will be instantaneous, and no need to be mined / solved through a hashing algorithm. For example: If we achieve 500,000 transactions in the span of 90 days, our BT is 5555. We can then take that and plug it into the next formula to calculate the VT (Value of Token). To find the VT, we plug in the BT and divide it by the TC (number of tokens in circulation). VT = BT / TC If we start off with 1,000,000 tokens in circulation and a BT value of 5555, we divide that into the total number of tokens in circulation in the ecosystem. We will start with 1,000,000 tokens thus giving us a VT of $.005 after the first 500,000 transactions. After each block of 500,000 transactions is reached, we will deploy another 250,000 tokens into circulation. So long as the amount of time it takes to reach another block of 500,000 transactions and the BT continues to increase, it will keep the value of the token rising despite more tokens being introduced into circulation. The token release also ensures the ecosystem isn‚Äôt being flooded with tokens that could cause a supply glut. This chart illustrates what the ideal execution of Proof of Utility will look like in the JetSet ecosystem. The number of tokens in the marketplace will be controlled to prevent the potentially dangerous uncontrolled rise of the token value. By adding in tokens, we can stabilize the marketplace and ensure that all users understand how much their tokens are worth. It also gives investors peace of mind that the value of the token will rise in correlation with people using the network in absolute dollar terms rather than the nebulous metric of monthly or daily active users. The number of transactions correlates directly with the number of active users, and transactions give a better measure of token robustness. While 500,000 transactions may seem like an arbitrary number, it‚Äôs worth noting that in the world of cryptocurrency 500,000 transactions on a new coin would be an impressive benchmark. It would show a proof of adoption by users and showcase the usefulness of the token. Proof of Utility will not require staking and relies purely on users creating verifiable transactions. Because the blockchain will be made public and transactions tied to real users, the level of transparency will be unprecedented. This is a truly decentralized way of allowing a token economy to work as well, removing potential security vulnerabilities by not giving any one specific group or person the ability to influence a network either through hashing power or an unfairly large stake thus influencing consensus. We have set a threshold at the end of our 3rd round of financing that allows us to implement Proof of Utility as the ecosystem begins its organic growth and transactions on the mainnet start to increase. By utilizing a phased deployment, we can ensure fluctuations in the price of JETS tokens are kept to a minimum and price stability is maximized.",
    "url": "http://localhost:4000/just-the-docs/writing/JetSet%20-%20Whitepaper/",
    "relUrl": "/writing/JetSet%20-%20Whitepaper/"
  },
  "7": {
    "id": "7",
    "title": "Tutorial",
    "content": "Tutorial How to Connect your Ledger Nano S to MetaMask Note: The lates Google Chrome update has broken Ledger/MetaMask functionality, Brave browser is now recommended to use this until Ledger and MetaMask / Google fix the issue. In this tutorial I will explain how to connect your Ledger to MetaMask and how to view, receive or send Ethereum or tokens to or from your Ledger via MetaMask. This method can be used even if you normally use My Ether Wallet with your Ledger and requires no additional steps to use MetaMask instead, which has a far simpler interface. This is particularly useful if you transact regularly but want the added security of using a hardware wallet. What you need: Ledger Nano S A Computer Chrome installed Brave Browser Installed MetaMask installed If you need some help installing MetaMask Connect your Ledger to your computer connect your ledger and type in your PIN Your first step is to plug your Ledger into your computer. Ensure it powers on and then input the pin you chose when setting up your ledger. Select the Ethereum Application navigate to the ethereum app and open it Next you need to open the Ethereum application on your Nano S. You do this by switching through the applications installed on your Ledger by pressing down on either the left or right button to navigate through the applications. Once you have the Ethereum application selected, push down on both buttons to open the application. Make sure contract data is turned on scroll down to the settings option Once the Ethereum application is open, press the right side button until you locate the ‚ÄúSettings‚Äù option. Press down on both buttons to open the menu. press down both buttons on contract data The first item in the settings menu is ‚ÄúContract Data‚Äù. Push down both buttons to select it. press down both buttons to select yes Now navigate with the right side button to choose ‚ÄúYes‚Äù and then press down on both buttons to select it. Once you have set your ledger up like this the first time, you won‚Äôt have to do it again each time you want to use it with MetaMask. Your Ledger is now ready! Open MetaMask click on the metamask fox Since you have already installed MetaMask, you need to open up your Chrome browser, and click on the MetaMask fox to interact with the application. click on the avatar Next, you need to click on your avatar in the top right corner of MetaMask. The avatar on your version of MetaMask will look different to the one in the image, but is always located in the same place. This will open up the menu in black and will give you access to many options for customizing your MetaMask such as adding additional accounts, importing accounts and connecting a hardware wallet such as your Ledger Nano S. Connect MetaMask to your Ledger select hardware wallet Click on ‚ÄúConnect Hardware Wallet‚Äù select Ledger and click on connect The next screen that pops up is fairly self explanatory. Simply click on the ‚ÄúLedger‚Äù button to select it, and then click ‚ÄúCONNECT‚Äù select ledger live if your ledger has been updated to the latest firmware and you use ledger live, or select legacy if it has not been updated in some time Once you have connected your Ledger, you need to tell MetaMask how to read it. If you have updated your Ledger to the latest firmware and have been using the Ledger Live application, you should select ‚ÄúLedger Live‚Äù and if you have not updated it, you should select Legacy. If you are unsure, start by selecting Ledger Live and looking at the grey box below it for your address, and Ethereum balance. MetaMask automatically sorts the addresses on your Ledger by balance, so if you have an Ethereum balance in the same address, this is the easiest way to identify your account. If you don‚Äôt have an Ethereum balance on the address you want to connect, you need to identify the correct address by looking at the column with the 0x addresses to identify the correct one to choose. If the correct address isn‚Äôt showing up, go back to the drop down menu, select ‚ÄúLegacy‚Äù and try the above steps again. Once you have found the correct address (in this case, in the pink box), click ‚ÄúCONNECT‚Äù You are connected! your ledger is connected to metamask You‚Äôve now connected your Ledger to MetaMask. Now that you‚Äôre connected we‚Äôll talk about a few important bits of information on this page by referencing the colored boxes. Blue: The blue boxes display your Ethereum balance that is in the address you selected. If you use multiple addresses on your Ledger, you will not see those balances, only the balance of the account you selected during setup. Green: Clicking on this box will copy your Ethereum address to your computers clipboard for pasting later. Orange: Any transactions you send or receive to or from your Ledger via MetaMask will show up here. Note that any transactions made previously wont show up in MetaMask. Pink: If you are using this address to manage Ethereum tokens, you will want to click here to add your tokens. (This is a misleading button title. By clicking ‚ÄúADD TOKEN‚Äù you are not adding tokens to your address, but actually just telling MetaMask to display the balance of your tokens)",
    "url": "http://localhost:4000/just-the-docs/writing/Ledger%20on%20MetaMask%20-%20Tutorial/",
    "relUrl": "/writing/Ledger%20on%20MetaMask%20-%20Tutorial/"
  },
  "8": {
    "id": "8",
    "title": "Article / Blog",
    "content": "Blog / Article Building dApps with JavaScript and Menlo One Menlo One is a development framework written in Javascript which provides developers with a toolkit for building decentralized applications (dApps) which are hosted on cloud based Content Nodes. You can think of these dApps as ‚Äúweb-dApps‚Äù. Traditionally only a small part of the dApp is kept on a blockchain, leaving the rest of the application on a traditional centralized system. Menlo One solves that problem by storing all of the data on several decentralized systems (At launch it works with IPFS and Ethereum), and eliminates a single point of failure by mirroring the server-side applications on many independently operated servers. For developers who have been building Single Page Application (SPA) in the Node.js ecosystem, our framework will feel very familiar. A client-side SPA communicates with a server-side Node.JS backend via a RESTFul API, courtesy of Express. Express interacts with an ORM which then communicates with a database. However there are a few paradigm shifts to consider through with this classic model. There is not a single centralized server which the developers maintain. Instead the back-end is hosted by 3rd parties on -their- servers, and users connect to one of them. In the Menlo ecosystem, there are multiple independently operated servers all mirroring the same server-side Node app. We call these ‚Äúcontent nodes‚Äù. Users cannot use a web dApp without running a client app on their desktop, the Menlo Wallet. This app is responsible for the discovering and connecting to servers for the user to connect to. It also contains lite nodes of several blockchain systems, and it is responsible for interacting with the blockchain networks for the user. Lastly this app is responsible for validating data the user receives from the content nodes with the blockchain. A simple API is exposed for developers, and the complexity of the validation protocol is handled for the developer automatically. On the server-side, application data is not stored in a single, centralized database. When data is saved to the database, a second call is made to save that data to the blockchain. Servers run an application which handle the protocol for communicating with the blockchain. If you‚Äôre a developer new to decentralized systems, you might be surprised by the fact that all users coming to your dApp are automatically authenticated but, by default, are anonymous. The user does not log in with a traditional username and password, the user authenticates their identity with a cryptographic key pair. At launch, this is Ethereum, but it will be possible for the user to authenticate with several protocols. If the application requires 2FA or single-click sign on, Menlo comes bundled with an integration to Civic, a private, decentralized identity solution. Framework Components Menlo One comes bundled with everything you need to get started building a dApp. If you‚Äôre familiar with some of the ‚ÄúReact / Node hackathon starter kits‚Äù, its very much in the same vein. It comes with the following major components: A front-end starter kit with React. Though, because Menlo follows a very classic RESTful design pattern, it would be easy to use a different front-end framework or build your own. The Menlo Wallet which runs on on the client side. A content node docker configuration with Node.js preconfigured with h Express &amp; Mongoose configured to support Typescript to safely handle REST APIs, Mongo as the database to index content distributed in IPFS and an Ethereum node to have the latest metadata living on the block-chain. Kovan based deployed contracts the framework automatically uses to get you building on testnet quickly. Deployment scripts to easily push your dApp server side solution to a central repository where all content nodes pull from to host applications. In the spirit of many great frameworks, the goal of Menlo is to give you the skeleton so you can focus on the project itself. While protocol for the dApp to communicate with the blockchain can be complex especially for developers new to blockchain development, we‚Äôve abstracted most of that complexity away so you can focus on building for the user. However there are a few Menlo specific considerations when building your web-dApp. When the ORM makes CRUD operations to the database, Menlo middleware can be included so you can specify which data should also be persisted to the blockchain. Menlo middleware can be included in Express routes so that the client know‚Äôs to validate that data with the blockchain. Although all data is saved to a public system, some user data such as private messages has to be kept private. We provide an API to a client side library which encrypts messages at REST. Forward compatible for next generation blockchains Menlo One is a sort of ‚Äúsecond layer‚Äù on top of existing blockchain networks. The blockchain space is certain to rapidly evolve in the coming years. While Ethereum is currently king of the smart contract platforms, there are several faster and more efficient competitors currently trying to dethrone it. We‚Äôve designed an API so that the underlying blockchain upon which the app is build can be swapped out without breaking changes, in the same way a properly built ORM is blockchain agnostic. FAQ: Why decentralize in the first place? If you‚Äôre new to decentralized systems, this might seem like we‚Äôve turned classic web architecture on its head a bit, and we have, but for good reason. The general idea is that we should assume the server is not trustworthy, and the user is afraid the server will give them content different from what the content creator intended. Imagine if your friend makes a blog post entitled ‚ÄúUSA Spies on Russia‚Äù, but then the Commander in Chief asks the Medium CEO to please change that text to ‚ÄúUSA is spied on by Russia‚Äù. If not for Menlo One, you would have no way of verifying if that‚Äôs what your friend intended you to read. With our framework, you the user would take a hash of the server response and compare that with a hash of the original message your friend left in a smart contract on a blockchain. That way both of you know you received the intended message, or if the content node is has been malicious. FAQ: Who will pay for the cost of hosting content nodes and the users blockchain GAS? In short there are three actors to consider in this ecosystem: The publisher (someone publishing some sort of data or content), the content node (someone hosting that data), and the user (someone consuming that content). In the Menlo One framework the publisher buys or earns Menlo‚Äôs ONE tokens, and when posting their message somewhere puts some ONE tokens in a smart contract. ONE is used to pay the content node for serving you the intended data. ONE is also used to reimburse the user for the inherent cost of using the Ethereum network. Furthermore, the user could be paid far more than the cost of GAS if the user is someone the publisher things is high value. For instance if the publisher was a car salesmen on a decentralized Auto Trader, and the user has recently purchased several Lamborghinis, the publisher could incentivize the user for his valuable attention. Assuming all of the customers auto purchases were on the blockchain (and they will be one day soon), this is one of the first times in history that a salesperson can qualify a customer before a transaction. In this sense, we cut out the middlemen. Until now most online marketplaces are in the fortunate position of being an intermediary of a transaction and taking a fee. However with Menlo One (and many rapidly growing blockchain networks), it would be possible to build a version of Uber where the driver gets to set his own price, and he does not have to give a percent to Uber. The first version of Menlo One is designed around monetizing ‚Äúattention‚Äù, (which is to say, pays the user for validating data received from a content node). However in later versions we will build an API for customizing the publishers deployed smart contract so that a payout to the user occurs with another event, such as a purchase transaction. FAQ: If the middleman can no longer make money, why would anyone build an app? It seems there is an economic shift taking place. It‚Äôs no longer lucrative to build a venue for exchange, but instead a medium of exchange. We recommend you explore launching your own cryptocurrency, which is specifically suited for your use case. FAQ: Do I have to use the ONE token for all transactions? The ONE tokens is only used to pay for the transaction of data as a way of paying people running content nodes. You the developer are free to build your dApp as you please. The cost of running content nodes can be passed on to users, content creators or your dApp could pay for that cost depending on your scenarios. It would be entirely possible to build a decentralized version of Uber where the checkout process goes through a smart contract you control which takes a percent of the transaction. We‚Äôre intending our framework be used by many projects who are launching their own cryptocurrency. From the users perspective Menlo One is designed to work behind the scenes. You could make your Uber-like ‚ÄúCarToken‚Äù dApp with an interface build with Menlo, which predominantly features your token, but with Menlo working behind the scenes. In later versions we plan on integrating with a decentralized exchanges so users could even easily exchange their earned ONE tokens for another ERC20.",
    "url": "http://localhost:4000/just-the-docs/writing/Menlo%20One%20-%20Technical%20Article/",
    "relUrl": "/writing/Menlo%20One%20-%20Technical%20Article/"
  },
  "9": {
    "id": "9",
    "title": "Technical Documentation",
    "content": "Technical Documentation What is Menlo Menlo is a framework for rapidly developing decentralized applications (dApps). This framework is designed to provide users with a user experience on-par with the centralized apps they‚Äôre used to. While Menlo is different in many ways from ‚Äútraditional‚Äù web app and even dApps, if you‚Äôre familiar with the Single Page Applications style of webapp architecture, Menlo should be relatively easy to understand. It can be used to build a variety of dApps such as a censorship resistant social media site, a blog, a crypto enabled eCommerce site, or a even a crypto exchange. It consists of two major components: 1. Content Node A ‚ÄúContent Node‚Äù, which is a ‚Äúback end‚Äù NodeJS / Express application which sits on a web server. It‚Äôs essentially a server side caching system for blockchain data. It has RESTful routes designed to be consumed by the front end. It processes data coming in and performs CRUD operations. It‚Äôs not possible to actually Delete or Update data, but we‚Äôll get to that later. Data is not only stored on the Content Node, but also stored on IPFS and Ethereum, making Menlo apps decentralized and censorship resistant. This is quite different from how most dApps are built; our system caches data on a web server for speed so users who may not have any crypto can at still read the dApp, as well as for search engines to easily index content. https://github.com/MenloOne/content-node 2. Front End (Block Overflow) A ‚Äúfront end‚Äù single page application built in ReactJS. This is similar in many ways to a ‚Äútraditional‚Äù dApp. It makes asynchronous calls to the Content Node as well as interfaces with a Web3 provider (we recommend MetaMask) for transactions. We built a demo application (Block Overflow), a nod to our favorite developer Q&amp;A site, which has a wide variety of features common to many dApp use cases. It has many routes in place for actions such as posting content, upvoting, commenting, etc. The front end comes with Truffle and smart contract specific to the Q&amp;A site use case but is easily customizable. It also comes with many common front end nice-to-haves such as Sass, Material UI, and many interface elements like drop down menus and loading animation. https://github.com/MenloOne/block-overflow This version of Menlo is an alpha release, but we hope it will give you everything you need to build a fast, user friendly dApp at hackathon-like speed. Architecture of a Menlo dApp ![Menlo System Architecture](https://raw.githubusercontent.com/MenloOne/menlo-one-docs/master/docs-images/menlo-one-system-architecture.jpg ‚Äú‚Äù) Considerations Authentication: The users‚Äô Ethereum address is used to authenticate. This is a good way to authenticate a user without relying on centralized methods such as email or oAuth. Real Time Updates: When a user posts content, other users see it near instantly - even before it‚Äôs confirmed on Ethereum. On most dApps, users often have to wait for a block to confirm before anyone can see the content. This could take a few minutes and creates a bad user experience. Content Nodes keep a web socket open with all dApps it‚Äôs connected to for real time updates. Posts which are submitted to Ethereum but not yet confirmed have a grey color to indicate they‚Äôre still pending. Ethereum and IPFS: (used in conjunction) The Content Node understands Solidity stored hashes and can query the local IPFS instance in order to cache and return the hash and contents of IPFS in one contract state query. IPFS Pinning: One of the attributes of storing data on IPFS is that any data which is not requested at least once within a 24 hour period is removed. To ensure data is not lost, the Content Node uses the local IPFS service‚Äôs ‚Äúpinning‚Äù feature to prevent data loss. ¬†¬†¬†¬†Caution: If for some reason you shut down your Content Node you will lose your data unless someone else is ¬†¬†¬†¬†¬†requesting it. ¬†¬†¬†¬†Note: Block Overflow and Content Nodes currently store and request IFPS data in parallel from the CN IPFS service ¬†¬†¬†¬†¬†as well as Infura IPFS to provide a natural backup. About the demo app, Block Overflow ![Menlo Framework](https://raw.githubusercontent.com/MenloOne/menlo-one-docs/master/docs-images/menlo-one-docs_0012_1.png ‚Äú‚Äù) We built Block Overflow as the demo app for two reasons. This use case leverages several features which are common to many dApps such as offering bounties, conditional smart contract based token distribution, voting, and storing messages. This way you have a few examples to work from and adopt for your own dApp. We thought it would be useful if there was a Q&amp;A site where you can post a bounty if you need a question answered quickly. A technical User Journey of asking a question, answering, and voting A user presses the ‚ÄúAsk a question‚Äù button which scrolls them down the page to a form. The text box is a SimpleMDE WYSIWYG Markdown editor. This application requires users to offer a minimum bounty of 10 ONE Tokens to ask a question, but the user can add more if they wish. ![Menlo Framework](https://raw.githubusercontent.com/MenloOne/menlo-one-docs/master/docs-images/menlo-one-docs_0011_2.png ‚Äú‚Äù) When the user presses ‚ÄúPost Question‚Äù, the question is uploaded to IPFS and its IPFS hash is then tracked as part of the creation of a new Topic which in turn creates a Forum contract which will hold the answers posted. Although this happens as part of the MenloTopics contract, it is called via a call to the MenloToken transferAndCallTx method which allows a call to the MenloTopics contract and a payment of ONE tokens as the initial bounty. MetaMask prompts the user to approve the transaction. ¬†¬†¬†¬†Heads Up: Sometimes MetaMask pops an overlay to approve, sometimes it does not, and you have to click on the fox ¬†¬†¬†¬†¬†icon in the top of the window. It‚Äôs a little inconsistent. The fox will have a number on him as pictured below. ![Menlo Framework](https://raw.githubusercontent.com/MenloOne/menlo-one-docs/master/docs-images/menlo-one-docs_0010_3.png ‚Äú‚Äù) The front end app then calls the Content Node to tell it there is an ongoing topic creation transaction. The Content Node pulls the question from IPFS on caches the uncommitted transaction. Any time a new topic is posted, the Content Node sends a signal through websockets to connected clients that there is a new topic and for all clients to refresh. Even though the transaction is not yet confirmed on Ethereum, other users can see the new message. If the transaction is not confirmed within 6 hours, the Content Node purges the message. If the Content Node sees the posted transaction confirm, it pulls the official version of the question from Ethereum and notifies clients to refresh given the topic is now confirmed. After the transaction is confirmed, it‚Äôs assigned a unique link based on the new MenloForum smart contract created, and users can click through to view the post. There is a link at the top of the post linking to the Ethereum transaction from the user who posted it, so that other users can validate the message themselves manually if they choose to. You can also see the total value of the bounty, and the 24 hour countdown timer. ![Menlo Framework](https://raw.githubusercontent.com/MenloOne/menlo-one-docs/master/docs-images/menlo-one-docs_0009_4.png ‚Äú‚Äù) This question now has 24 hours to be answered. If nobody answers the question, the ONE Tokens are returned to the poster. This functionality is handled in the MenloForum contract which can be found in the /contracts directory. Whoever has the most upvoted reply is rewarded the bounty. Other users can now post answers to the questions. Users have to add 5 ONE Tokens to the bounty pool to post an answer. Other users can now upvote or downvote answers with the option of leaving a comment. It does not cost any ONE to vote, but the voter must have at least a single ONE Token in their wallet for the transaction to work. Each time an answer is posted, the countdown timer resets to 24h00m00s. The post closes once the countdown timer reaches 00h00m00s. At the end of the 24 hour window, the total bounty is transferred to the person with the most upvoted answer or back to the question poster. ¬†¬† Front End How to download and run Block Overflow locally on your computer. It‚Äôs possible to install the entire Block Overflow front end on your local machine. Out of the box the dApp points to the smart contracts and Content Node operated by the Menlo team for Block Overflow. You can of course launch your own Content Node; Prerequisites Node.js: If you do not already have it, you will need to install Node.js on your machine. We recommend the tutorials on the Node.js site. Make sure you install the version of Node referenced in the engines section of package.json. https://nodejs.org/en/download/package-manager/ Node Version Manager: You will need the right version of Node.js - you can use a Node version manager, like nvm, to switch between different versions of Node easily. There is a good tutorial on their Github: https://github.com/creationix/nvm MetaMask: An Ethereum wallet with a Web3 provider is required to use Block Overflow. We recommend the chrome extension MetaMask, but other Ethereum wallets such as Mist or Parity will work as well. You can find MetaMask at https://metamask.io/ Get some ETH: You will need a little bit of ETH. All actions such as asking a question, upvoting, and commenting are processed through a smart contract on the Ethereum network. Calling these smart contracts requires a little bit of ETH (aka GAS). You can of course buy ETH on nearly every exchange. After which send some to your MetaMask wallet. Get some ONE Tokens: The Menlo ONE Token is required to use Block Overflow. The ONE Token has a special function (TransferAndCall) which the smart contracts for posting and replying depend on. It allows a client to send ONE tokens and perform a function on the token receiving contract in one atomic solidity call. You can get ONE from several exchanges including Bitmart https://www.bitmart.com/trade/en?symbol=ONE_ETH and IDEX https://idex.market/eth/one . After which send some to your MetaMask wallet. Add the ONE token to MetaMask: It‚Äôs always handy to see your ONE token balance in your MetaMask wallet. At the time of this writing you have to add the ONE token address manually. Click ‚Äúadd token‚Äù and enter the ONE Token‚Äôs address which is: 0x4d807509aece24c0fa5a102b6a3b059ec6e14392 We also put together a separate tutorial on this here. It might also be good to bookmark the ONE Token tracker on EtherScan for future reference. https://etherscan.io/token/0x4d807509aece24c0fa5a102b6a3b059ec6e14392 Running Block Overflow Locally git clone https://github.com/MenloOne/block-overflow.git cd block-overflow nvm use 8.11.4 npm install npm run build npm run dev That‚Äôs it! After running the last command, a tab should open up in chrome pointing at http://localhost:3000 Because it‚Äôs reading from the Menlo Team Content Node, you should see content and should look something like the image below. You‚Äôre now apart of the web 3.0. Troubleshooting If you any problems install the dependencies, you might want to switch to NPM v5.10.0 - You may have mixed results with other versions. The easiest way is to delete the block-overflow folder and start again from scratch, but run npm install npm@5.10.0 before npm install If you have any other problems, please feel free to ask for a hand in the Menlo Telegram channel https://t.me/Menloone or you could your question on the public version of Block Overflow. https://blockoverflow.menlo.one/ Installing Block Overflow on a web server There is not much difference between running Block Overflow on your computer or on a web server such as AWS or Heroku. It‚Äôs a React dApp pointing at the Menlo Team Content Node. Heroku is probably your easiest option and Block Overflow will run on one of their default NodeJS boxes. ¬†¬† Content Node How to install a Content Node on AWS In this section we‚Äôre going to install a Content Node which includes IPFS and Ethereum on AWS. Things to do Create an AWS account Launch an EC2 box with Ubuntu SSH into your instance Install Golang and IPFS Setup SSL Certs Configure NGINGX Install GETH Install and build Content Node software Create an AWS account Go to AWS, sign in or click on create AWS account. Choose Personal Account unless you have a business setup, for which you will need the company details. You will have to enter your card details for a small refundable charge to verify your identity. Once the registration is confirmed, you can go to the console. ![Menlo Framework](https://raw.githubusercontent.com/MenloOne/menlo-one-docs/master/docs-images/menlo-one-docs_0007_6.png ‚Äú‚Äù) Launch an EC2 instance Now that the account is setup, you are ready to launch an EC2 instance. Type Ubuntu in the search bar and select the your server. Make sure 64-bit (x86) is checked. ![Menlo Framework](https://raw.githubusercontent.com/MenloOne/menlo-one-docs/master/docs-images/menlo-one-docs_0006_7.png ‚Äú‚Äù) Select a large enough instance. m4.2xlarge will work. ![Menlo Framework](https://raw.githubusercontent.com/MenloOne/menlo-one-docs/master/docs-images/menlo-one-docs_0005_8.png ‚Äú‚Äù) Ensure you have at least 2 Terabytes of storage. ![Menlo Framework](https://raw.githubusercontent.com/MenloOne/menlo-one-docs/master/docs-images/menlo-one-docs_0004_9.png ‚Äú‚Äù) Set up security groups appropriately. Select Review and Launch (other settings can be configured later if needed). The next screen might show a warning about the security of the instance and changing security group settings. You can ignore this for now. Go ahead and click Launch. ![Menlo Framework](https://raw.githubusercontent.com/MenloOne/menlo-one-docs/master/docs-images/menlo-one-docs_0003_10.png ‚Äú‚Äù) On the next screen, you will be asked to create a key pair which allows you to SSH into your instance. Follow the instructions to create a custom name key pair and store it somewhere on your PC where you can access it later. ![Menlo Framework](https://raw.githubusercontent.com/MenloOne/menlo-one-docs/master/docs-images/menlo-one-docs_0002_11.png ‚Äú‚Äù) SSH into your instance ![Menlo Framework](https://raw.githubusercontent.com/MenloOne/menlo-one-docs/master/docs-images/menlo-one-docs_0000_13.png ‚Äú‚Äù) Creating a Content Node box on AWS You can follow the IPFS AWS Tutorial Note: For almost all of these commands you have to be root - therefore we suggest doing sudo bash at the beginning and running the rest of the commands as root: sudo bash Initialize and mount the EBS volume lsblk Lists out the devices you have on the EC2 instance. For example: NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT loop0 7:0 0 87.9M 1 loop /snap/core/5328 loop1 7:1 0 12.7M 1 loop /snap/amazon-ssm-agent/495 nvme0n1 259:0 0 100G 0 disk ‚îî‚îÄnvme0n1p1 259:1 0 100G 0 part / nvme1n1 259:2 0 3T 0 disk In this example, it‚Äôs nvme1n1 that is a 3T volume type disk but that has not yet been mounted. It will not have a file system on it initially which you can check and verify with the command: &gt; file -s /dev/nvme1n /dev/nvme1n1: data The response is data because there is no file system. So, lets initialize a file system and mount the drive: &gt; mkfs -t ext4 /dev/nvme1n1 &gt; mkdir /data &gt; file -s /dev/nvme0n1p1 /dev/nvme1n1: Linux rev 1.0 ext4 filesystem data, UUID=12f0dd42-6a60-4966-a62a-e3134c706cae (extents) (64bit) (large files) (huge files) You will see a UUID listed as the unique ID of this device. Use that to mount it in fstab in order to mount the volume on every reboot: cat &gt;&gt; /etc/fstab &lt;&lt;EOL /dev/disk/by-uuid/12f0dd42-6a60-4966-a62a-e3134c706cae /data ext4 defaults,nofail 0 2 EOL mount -a Install Golang and IPFS apt-get update -y apt-get install -y golang wget https://dist.ipfs.io/go-ipfs/v0.4.15/go-ipfs_v0.4.15_linux-amd64.tar.gz tar -xvf go-ipfs_v0.4.15_linux-amd64.tar.gz Move executable to your bin path mv go-ipfs/ipfs /usr/local/bin rm -rf go-ipfs Initialize IPFS echo &#39;export IPFS_PATH=/data/ipfs&#39; &gt;&gt;~/.bash_profile source ~/.bash_profile mkdir -p $IPFS_PATH ipfs init -p server Configure IPFS Limits &amp; CORS ipfs config Datastore.StorageMax 20GB ipfs config Addresses.API /ip4/127.0.0.1/tcp/5001 ipfs config --json API.HTTPHeaders.Access-Control-Allow-Origin &#39;[&quot;*&quot;]&#39; ipfs config --json API.HTTPHeaders.Access-Control-Allow-Methods &#39;[&quot;PUT&quot;, &quot;GET&quot;, &quot;POST&quot;]&#39; ipfs config --json Addresses.Swarm &#39;[&quot;/ip4/0.0.0.0/tcp/4001&quot;, &quot;/ip4/0.0.0.0/tcp/8081/ws&quot;, &quot;/ip6/::/tcp/4001&quot;]&#39; ipfs config --bool Swarm.EnableRelayHop true To surface the gateway over HTTP ipfs config Addresses.Gateway /ip4/0.0.0.0/tcp/8080 Copy and paste unit file definition cat &gt;/lib/systemd/system/ipfs.service &lt;&lt;EOL [Unit] Description=ipfs daemon [Service] ExecStart=/usr/local/bin/ipfs daemon --enable-gc Restart=always User=root Group=root Environment=&quot;IPFS_PATH=/data/ipfs&quot; [Install] WantedBy=multi-user.target EOL Start IPFS systemctl daemon-reload systemctl enable ipfs systemctl start ipfs.service You can now reboot your instance and make sure IPFS is running by: systemctl restart ipfs systemctl status ipfs Get Certbot to get an SSL Cert From https://certbot.eff.org/ apt-get install -y software-properties-common add-apt-repository ppa:certbot/certbot apt-get update -y apt-get install -y python-certbot-nginx Use CertBot to get your SSLs for IPFS.menlo.one and CN.menlo.one First point cn.menlo.one (or your domain) to your AWS box. Then: cat &gt;/etc/nginx/sites-available/default &lt;&lt;EOL EOL certbot --nginx -d cn.menlo.one certbot --nginx -d ipfs.menlo.one Setup automatic SSL renewals cat &gt;/etc/console-setup/renew-cert &lt;&lt;EOL #!/bin/bash certbot renew --noninteractive EOL chmod +x /etc/console-setup/renew-cert Configure NGINGX cat &gt;/etc/nginx/sites-available/default &lt;&lt;EOL server { server_name ipfs.menlo.one; listen [::]:4002 ssl ipv6only=on; listen 4002 ssl; ssl_certificate /etc/letsencrypt/live/ipfs.menlo.one/fullchain.pem; # managed by Certbot ssl_certificate_key /etc/letsencrypt/live/ipfs.menlo.one/privkey.pem; # managed by Certbot include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot location / { proxy_pass http://127.0.0.1:5001; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;upgrade&quot;; } } server { server_name ipfs.menlo.one; listen 80 ; listen [::]:80 ; if ( $host = ipfs.menlo.one) { return 301 https:// $host $request_uri; } # managed by Certbot return 404; # managed by Certbot } server { server_name cn.menlo.one; # managed by Certbot listen [::]:443 ssl ipv6only=on; # managed by Certbot listen 443 ssl; # managed by Certbot location / { # redirect all HTTPS traffic to localhost:5005 proxy_pass http://127.0.0.1:5005; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $host; proxy_cache_bypass $http_upgrade; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; # WebSocket support proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $http_connection; } location /socket.io { # redirect all HTTPS traffic to localhost:5005 proxy_pass http://127.0.0.1:5005; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $host; proxy_cache_bypass $http_upgrade; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; # WebSocket support proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $http_connection; } ssl_certificate /etc/letsencrypt/live/cn.menlo.one/fullchain.pem; # managed by Certbot ssl_certificate_key /etc/letsencrypt/live/cn.menlo.one/privkey.pem; # managed by Certbot include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot } server { server_name cn.menlo.one; listen 80 ; listen [::]:80 ; if ( $host = cn.menlo.one) { return 301 https:// $host $request_uri; } # managed by Certbot return 404; # managed by Certbot } EOL Test CORS You can test this config by doing: curl -H &quot;Origin: http://expo.menlo.com&quot; -H &quot;Access-Control-Request-Method: POST&quot; -H &quot;Access-Control-Request-Headers: X-Requested-With&quot; --verbose http://0.0.0.0:5001/api/v0/swarm/peers; echo Restart NGINX systemctl restart nginx Install GETH add-apt-repository -y ppa:ethereum/ethereum apt-get update -y apt-get install -y ethereum echo &#39;export RINKEBY_PATH=/data/geth/rinkeby&#39; &gt;&gt;~/.bash_profile echo &#39;export MAINNET_PATH=/data/geth/mainnet&#39; &gt;&gt;~/.bash_profile source ~/.bash_profile cat &gt;/lib/systemd/system/geth.service &lt;&lt;EOL [Unit] Description=geth node [Service] ExecStart=/usr/bin/geth --syncmode &quot;fast&quot; --rpc --rpcapi db,eth,net,web3,personal --ws --wsorigins &quot;*&quot; --cache=1024 --rpcport 8545 --rpcaddr 127.0.0.1 --rpccorsdomain &quot;*&quot; --datadir /data/geth/mainnet --mine --etherbase &quot;0x5421a9B25218f3566c11e5D350aa91369627764B&quot; Restart=always User=root Group=root [Install] WantedBy=multi-user.target EOL systemctl daemon-reload systemctl enable geth systemctl start geth.service To interact with Geth Viewing the log: journalctl -f -t geth Attaching to the console: geth --datadir=$MAINNET_PATH attach ipc:$MAINNET_PATH/geth.ipc console Rudimentary track of sync Attach to the geth console and enter this script: var lastPercentage = 0;var lastBlocksToGo = 0;var timeInterval = 10000; setInterval(function(){ var percentage = eth.syncing.currentBlock/eth.syncing.highestBlock*100; var percentagePerTime = percentage - lastPercentage; var blocksToGo = eth.syncing.highestBlock - eth.syncing.currentBlock; var bps = (lastBlocksToGo - blocksToGo) / (timeInterval / 1000) var etas = 100 / percentagePerTime * (timeInterval / 1000) var etaM = parseInt(etas/60,10); console.log(parseInt(percentage,10)+&#39;% ETA: &#39;+etaM+&#39; minutes @ &#39;+bps+&#39;bps&#39;); lastPercentage = percentage;lastBlocksToGo = blocksToGo; },timeInterval); Install and build Content Node software mkdir /data/content-node chown ubuntu:ubuntu /data/content-node Exit out of sudo bash cd /data/content-node git init git remote add origin https://github.com/docs-images/MenloOne/content-node.git git pull origin master Then‚Ä¶ sudo bash apt install nodejs apt install npm npm i -g npm@5.6.0 npm i npm run build Make CN a service cat &gt;/lib/systemd/system/cn.service &lt;&lt;EOL [Unit] Description=content node daemon [Service] ExecStart=/usr/local/bin/npm start --prefix /data/content-node Restart=always User=root Group=root Environment=&quot;&quot; [Install] WantedBy=multi-user.target EOL systemctl daemon-reload systemctl enable cn systemctl start cn ¬†¬† Testing &amp; Playing Around See the post content on IPFS All the data on Menlo is stored on IPFS. You can see the data on IPFS yourself by following these steps: Find a topic such as https://blockoverflow.menlo.one/topic/0xFDCf0803e6A8C4fAb877dD7d8A6FD173832FB441 Copy the topic ID, such as 0xFDCf0803e6A8C4fAb877dD7d8A6FD173832FB441 Paste into the API endpoint https://cn.menlo.one/v0/forums/ &lt; topic ID &gt;, such as: https://cn.menlo.one/v0/forums/0xFDCf0803e6A8C4fAb877dD7d8A6FD173832FB441. This will give you the JSON response which contains the IPFS content addressable hash‚Äôs. Look for an array called messageHashes. I recommend using a Chrome plugin which makes the JSON easier to read. I like this one. Copy a message hash such as QmcVBbB31sKvJS6wJCi98ERjVYLvbasTMkzeby7qe5Z386. You will need IPFS to view it. If you have IPFS installed, you can run IPFS locally by entering ipfs daemon via command line. Or you can use an online service. Paste the hash in either Online: https://ipfs.io/ipfs/ hash ID Local: http://localhost:8080/ipfs/ hash ID Then you can verify that the data is on IPFS. ![Menlo IPFS Preview](https://raw.githubusercontent.com/MenloOne/menlo-one-docs/master/docs-images/menlo-one-docs_ipfs_preview.jpg ‚Äú‚Äù) Important Info Block Overflow Directory Layout . ‚îú‚îÄ‚îÄ build # ‚îÇ ‚îî‚îÄ‚îÄ static # ‚îÇ ‚îú‚îÄ‚îÄ css # ‚îÇ ‚îú‚îÄ‚îÄ js # ‚îÇ ‚îî‚îÄ‚îÄ media # ‚îú‚îÄ‚îÄ config # ‚îÇ ‚îî‚îÄ‚îÄ jest # ‚îú‚îÄ‚îÄ contracts # ‚îú‚îÄ‚îÄ contracts.src # ‚îú‚îÄ‚îÄ migrations # ‚îú‚îÄ‚îÄ network # ‚îú‚îÄ‚îÄ public # ‚îú‚îÄ‚îÄ scripts # ‚îÇ ‚îî‚îÄ‚îÄ utils # ‚îú‚îÄ‚îÄ server # ‚îú‚îÄ‚îÄ src # ‚îÇ ‚îú‚îÄ‚îÄ ContentNode # ‚îÇ ‚îú‚îÄ‚îÄ answers # ‚îÇ ‚îú‚îÄ‚îÄ artifacts # ‚îÇ ‚îú‚îÄ‚îÄ components # ‚îÇ ‚îú‚îÄ‚îÄ contracts # ‚îÇ ‚îú‚îÄ‚îÄ images # ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ PagesToChop ‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ images ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ discover ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ guild # ‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ members ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ menlo # ‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ team-logos ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ progress ‚îÇ ‚îú‚îÄ‚îÄ internals # ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ config # ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ test # ‚îÇ ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ helpers ‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ pages ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ webpack # ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ utils ‚îÇ ‚îú‚îÄ‚îÄ models # ‚îÇ ‚îú‚îÄ‚îÄ pages # ‚îÇ ‚îú‚îÄ‚îÄ questions # ‚îÇ ‚îú‚îÄ‚îÄ storage # ‚îÇ ‚îú‚îÄ‚îÄ styles # ‚îÇ ‚îî‚îÄ‚îÄ utils # ‚îú‚îÄ‚îÄ test # ‚îÇ ‚îî‚îÄ‚îÄ helpers # ‚îî‚îÄ‚îÄ types # Content Node Directory Layout . # ‚îú‚îÄ‚îÄ contracts # ‚îú‚îÄ‚îÄ migrations # ‚îú‚îÄ‚îÄ network # ‚îú‚îÄ‚îÄ scripts # ‚îú‚îÄ‚îÄ src # ‚îÇ ‚îú‚îÄ‚îÄ ContentNode # ‚îÇ ‚îú‚îÄ‚îÄ artifacts # ‚îÇ ‚îú‚îÄ‚îÄ services # ‚îÇ ‚îú‚îÄ‚îÄ storage # ‚îÇ ‚îî‚îÄ‚îÄ utils # ‚îî‚îÄ‚îÄ test # How Do I Change the contract? If you want to change the MenloTopics or MenloForum contracts, you will need to change several files across the front end and Content Node. Lets take changing MenloForum as an example: In the front end (block-overflow): File: contracts.src/MenloForum.sol npm run build to build the typescript files that are generated from the .sol and to flatten the solidity files for ease of use with etherscan. Change any .ts files that use MenloForum functions Do truffle deploy --network rinkeby --reset to compile and deploy the new contract. Put the address of the new contract in src/models/networks.ts Update src/ContentNode/BlockOverflow.cto.ts to include any new fields in the contract that the front end wants returned. In the content-node: Copy the front end file contracts/MenloForum.sol into contracts/. npm run build to generate the typescript files. Copy the new contract‚Äôs address from src/models/networks.ts in the front end to src/services/networks.ts in the Content Node. Update src/ContentNode/BlockOverflow.cto.ts from the front end to the Content Node src/ContentNode Update src/services/Forum.ts to read and include the new state in the GET method. If you look at the code in src/services/Forum.ts or src/services/Topics.ts all they really do is read the state of the contract, track events and cache them in an array and track any transactions that change state so the Content Node can use websockets to notify clients that they should refresh the contract state. All of the state of a contract is returned in one GET call making interactions between front end and Content Node very efficient. ¬†¬† Moving Forward We want the above process of changing or adding contracts to be considerably simpler. In the future we aim to make setup as easy as: Create a .zip package containing the .artifact file generated by truffle compile for a contract to cache along with a markup content-node.json file that describes some of the relationships not specified in the artifacts file about the contract. Copy the .zip file into a content-node folder Surface a generic GraphQL interface from the CN to access the contract state across any of these contracts The content-node.json markup file would express relationships not otherwise known from the .sol file like: Which addresses are actually IPFS hashes - the Content Node would then automatically surface the contents of the IPFS file as inline JSON for the object. Which addresses are addresses to ‚Äúchildren‚Äù contracts. E.g. MenloTopics issues an Event any time a new topic is created which includes the address to the MenloForum contract it creates. Which arrays can be appended to by the client in as uncommitted so all clients see uncommited items of that array until the blockchain gets around to committing them. ¬†¬† How to Contribute Anyone and everyone is welcome to contribute to this project. The best way to start is by checking our open issues, submit a new issue or feature request, participate in discussions, upvote or downvote the issues you like or dislike, send pull requests. Or, if you think you can help accomplish what‚Äôs in the ‚ÄúMoving Forward‚Äù section above, we‚Äôd love to help you create a branch and a proper path forward toward that functionality. Future Goals Using artifacts ABI files to programmatically cache contract state for any contract. Understanding content-node.json markup files for programmatic caching of IPFS JSON content and uncommitted additions. Handling markup + ABI in .zip files. Adding GraphQL over MongoDB for caching and querying instead of in-memory. Client side validation of data. Integration of Civic for more robust authentication. A React Native front end and more mobile responsive layout. Smoother integration with MetaMask. A Menlo specific wallet.",
    "url": "http://localhost:4000/just-the-docs/writing/Menlo%20One%20-%20Technical%20Documentation/",
    "relUrl": "/writing/Menlo%20One%20-%20Technical%20Documentation/"
  },
  "10": {
    "id": "10",
    "title": "Whitepaper Extract 1",
    "content": "Whitepaper Extract Authentication &amp; User Data End users essentially authenticate with their private key for any actions which require a write to the system such as posting, voting, commenting etc. All user data is associated with their key. This includes messages associations, vote count, messages payout etc. Of course payout in the Menlo One Token is also made to the users address. This key pair authentication design pattern is becoming common place within decentralized systems, and while we think the pros outweigh the cons, it‚Äôs not without its flaws. The clear advantage to this is the ability to authenticate without relying on an intermediary, the disadvantage is the end-user losing their private key or their private key being compromised. A major reason why the ERC20 standard makes sense for for Menlo Token (ONE) is how easy the token is to transfer. If a user suspects their key has been compromised, they can transfer their ONE to a fresh account. Many ERC20 compatible wallets also support the easy creation of an easy to backup mnemonic phrase. If handled responsibly, using a key pair for authentication makes a lot of sense. Though we recommend developers using Townhall to include information for their end-users on how to responsibly store and use their keys. Data Model Text based messages such as topics and comments follow the InterPlanetary Linked Data (IPLD) format which is then converted into Concise Binary Object Representation (CBOR) by IPFS. IPLD allows data on IPFS to treat all content-addressed data structures as subsets of one big information space, unifying all data models that link data with hashes as instances of IPLD [104]. An example of a message JSON object: { &quot;version&quot;: &lt;hash&gt;, &quot;parent&quot;: &lt;hash&gt;, &quot;body&quot;: &lt;string&gt;, &quot;issuer&quot;: &lt;pubkey&gt; } Structure of a TownHall message object model Root Messages ‚Äî-Topics ‚Äî-Comments Core Features TownHall comes with the following system features Create Topic Comment on topic Upvote topic Downvote topic Upvote comment Downvote comment The TownHall interface comes with the following features View all messages Input box to submit a new message Buttons for upvote, downvote Button to ‚Äúget paid for your messages‚Äù Text which says ‚Äúthis post earned X ONE‚Äù by that message",
    "url": "http://localhost:4000/just-the-docs/writing/Menlo%20One%20-%20Whitepaper/",
    "relUrl": "/writing/Menlo%20One%20-%20Whitepaper/"
  },
  "11": {
    "id": "11",
    "title": "Block Overflow (ONE)",
    "content": "Blockchain Block Overflow Block Overflow is a dApp similar to Stack Overflow. It differs, however, in that developers who are able to answer gets paid to do so if they provide the most valuable answer. Block overflow is built on a Menlo One Content Node, which has decentralizing properties, it however is still able to deliver content and information as fast as a cloud server, with the benefits of blockchain technology. Things I Worked On: Strategy Branding &amp; Marketing Product Development Copywriting Project Management Content Generation Things I Learned About: Web3 Integrations Smart Contract Development IPFS Distributions",
    "url": "http://localhost:4000/just-the-docs/projects/Project%20-%20Block%20Overflow/",
    "relUrl": "/projects/Project%20-%20Block%20Overflow/"
  },
  "12": {
    "id": "12",
    "title": "HempCoin (THC)",
    "content": "Blockchain HempCoin Being one of the oldest surviving Gen 1 Cryptocurrencies, it was a complete honour to be asked to work on the relaunch of THC. I worked with the team on pruduct development, and the move from just a cryptocurrency to a focus on agriculture, medicinal marijuana stores and the idea of using a cryptocurrency in dispensaries for customers and suppliers to minimise the security expenses that these business need to employ in order to keep their staff and customers safe. I also worked on marketing and their copy. Things I Worked On: Strategy Content Creation Product Development Copywriting Things I Learned About: The Cannabis Industry Pain Points Consumer Study Dispensary, Grower and Distribution Hazards",
    "url": "http://localhost:4000/just-the-docs/projects/Project%20-%20HempCoin/",
    "relUrl": "/projects/Project%20-%20HempCoin/"
  },
  "13": {
    "id": "13",
    "title": "PIMeo",
    "content": "B2B PIMeo PIMeo, a tool for workers on construction sites and in the civil engineering sector to accurately calculate costs, materials required and perform other engineering calculations as well as a full project management suite that provides users with tools for the Agile and PRINCE2 methodologies to manage multi-million euro construction projects was brought to our team at Dev200. I worked with the client to develop their concepts, calculations and user interface to ensure that the software was easily useable by anyone, regardless of their technological experience level. Things I Worked On: Strategy Branding &amp; Marketing Product Development Copywriting Project Management Content Generation UI / UX Design Things I Learned About: Civil Engineering Controls and Verifications Process Compliance and Testing",
    "url": "http://localhost:4000/just-the-docs/projects/Project%20-%20PIMeo/",
    "relUrl": "/projects/Project%20-%20PIMeo/"
  },
  "14": {
    "id": "14",
    "title": "RealFevr",
    "content": "Blockchain RealFevr RealFevr is a online fantasy sports platform that was launched in 2014, since then they have been looking for a way in which to monetize their platform. I worked with the team to develop a prototype of a crypto-fueled version of the platform that not only allowed for wagering between users who compete in the same fantasy league, but also to use a token such as ERC721‚Äôs to provide ‚Äúownership‚Äù of players, and in game player trading much like actual football teams would. The product is due for release in 2019. Things I Worked On: Strategy Branding &amp; Marketing Product Development Content Creation Things I Learned About: Fantasy Leagues Sports Betting Football Hedging and Leveraging",
    "url": "http://localhost:4000/just-the-docs/projects/Project%20-%20RealFevr/",
    "relUrl": "/projects/Project%20-%20RealFevr/"
  },
  "15": {
    "id": "15",
    "title": "Solaris (XLR)",
    "content": "Blockchain Solaris (XLR) Solaris was originally built as an environmentally friendly cryptocurrency. In late 2017, the decision was taken to re-think the currency and its features and I was taken on board to assist in developing the team‚Äôs vision for a privacy coin. I worked alongside the team on branding, the whitepaper, marketing and product feature development. The coin successfully relaunched in 2018. Things I Worked On: Strategy Branding &amp; Marketing Product Development Copywriting Things I Learned About: Privacy Based Cryptocurrencies Target Market Is Optional Privacy Still Privacy? Reward Mechanisms Blockchain Development Balancing Energy Consumption and Security Private Cryptographic Functions",
    "url": "http://localhost:4000/just-the-docs/projects/Project%20-%20Solaris/",
    "relUrl": "/projects/Project%20-%20Solaris/"
  },
  "16": {
    "id": "16",
    "title": "BeatzCoin (XLR)",
    "content": "Blockchain BeatzCoin BeatzCoin is a platform for creators to upload, store, market, rent and sell their content to users with the added benefits of being able to crowdfund and sell merchandise and event tickets directly to their subscribers and fans. Users can view or listen to content created by artists on your desktop or mobile wherein creators and users are able to earn and spend revenue in a fair system that is user and creator centric. Things I Worked On: Branding &amp; Marketing Product Development Content Creation White Paper Creation Fun Information John McAfee tweeted about this project, and being the writer and product developer behind many of the concepts in the whitepaper, I think it‚Äôs pretty cool!",
    "url": "http://localhost:4000/just-the-docs/projects/Project%20-%20VibraVid/",
    "relUrl": "/projects/Project%20-%20VibraVid/"
  },
  "17": {
    "id": "17",
    "title": "World Health Organization",
    "content": "Non Profit World Health Organization Infection prevention and control (IPC) is a scientific approach and practical solution designed to prevent harm caused by infection to patients and health workers. It is grounded in infectious diseases, epidemiology, social science and health system strengthening. IPC occupies a unique position in the field of patient safety and quality universal health coverage since it is relevant to health workers and patients at every single health-care encounter. I worked with the Dev 200 team to plan, build and develop a mobile application for iOS and Android to be deployed throughout Africa to educate people on infection and disease prevention. Things I Worked On: Product Development Project Management UI / UX Design",
    "url": "http://localhost:4000/just-the-docs/projects/Project%20-%20WHO/",
    "relUrl": "/projects/Project%20-%20WHO/"
  },
  "18": {
    "id": "18",
    "title": "Projects",
    "content": "Projects",
    "url": "http://localhost:4000/just-the-docs/Projects",
    "relUrl": "/Projects"
  },
  "19": {
    "id": "19",
    "title": "Support",
    "content": "Where to get help If you think you‚Äôve found a bug in The Dinky Theme, please check the existing issues, and if no one has reported the problem, open a new issue. If you have a general question about the theme, how to implement it, or how to customize it for your site you have two options: Contact GitHub Support, or Ask your question of the Jekyll community on talk.jekyllrb.com",
    "url": "http://localhost:4000/just-the-docs/SUPPORT/",
    "relUrl": "/SUPPORT/"
  },
  "20": {
    "id": "20",
    "title": "Skills",
    "content": "Skills Marketing &amp; Growth Skill Experience Sentiment Analysis 6 Years Analytics 3 Years User Acquisition 2.5 Years Hyper Growth 2 Years Developer Growth 1.5 Years Customer Success 1 Year SEO &lt;1 Year Project Skill Experience Project Scheduling 10 Years Project Planning 10 Years Project Management 9 Years Product Development 4 Years Product Management 4.5 Years Product Ownership 3 Years Developer Skill Experience HTML 13 Years CSS 9 Years Solidity 1,5 Years JavaScript 5 Years Ruby 1 Year Python &lt; 1 Year Creative Skill Experience Video Editing 10 Years Graphic Design 3 Years Content Writing 6 Years Technical Writing 4 Years UI / UX Design 2.5 Years",
    "url": "http://localhost:4000/just-the-docs/Skills",
    "relUrl": "/Skills"
  },
  "21": {
    "id": "21",
    "title": "Whitepaper Extract 2",
    "content": "Whitepaper Extract 4. Feature Set 4.1. Proof-of-Stake Solaris operates with a Proof-of-Stake consensus mechanism, meaning that anyone who can prove they hold XLR can help secure the network, i.e., has a chance to create the newest block. Unlike masternodes , there is no barrier for entry to start staking XLR. Staking participants only need to prove that they own a minimum of 1 XLR. This is achieved by having mature coins in your wallet or node, which is enabled for Staking. Any participant who does this is considered a validator, and the network of validators then participate in the consensus algorithm. 4.2. Masternodes The purpose of masternodes in the Solaris network is the processing of functions, thus aiding in the creation of new blocks. Just like Stakers, Masternodes receive part of the block reward for their participation in the network. A masternode is a full node or computer wallet that keeps the full copy of the blockchain in real-time. They are however, quite different in their functionality compared to normal nodes in that they perform several other functions. Solaris has implemented the following masternode features in XLR: Privacy Increase through the Zerocoin protocol Instant Transactions through SwiftTX Governance and Voting Budgeting and Treasury Masternodes are not standalone nodes, they are in constant communication with other masternodes to create the decentralized network that Solaris aimed to create. 4.2.1. Masternode Requirements There are many ways to set up a masternode, you may choose to run your own computer, or use a VPS (Virtual Private Server) for example. To run a masternode there are a few requirements: A Fully Synced Wallet 1000 XLR which are not spendable while you run a masternode A computer or VPS 4.3. SwiftTX SwiftTX transactions are confirmed and spendable within seconds. These funds are guaranteed by the Solaris network of masternodes. There is no need to wait for multiple confirmations as is normally expected in order to be confident in the validity of the transaction. 4.4. ZeroCoin Protocol Zerocoin provides full privacy to our users. Our implementation of the Zerocoin protocol converts your publicly available transaction details into an anonymous one. When a user wishes to spend funds, they appear as a new coin without a spending history or origin. This protocol uses cryptographically secure techniques to ensure that your coins cannot be traced. This allows you to transact with your coins freely with strong mathematical assurances that the transactions are not traceable. These assurances remain in place even if the network is compromised. 4.5. Sporks A multi-phased fork, or spork is a system previously unique to DASH, which is used to safely implement new features to the network through network-level variables. This is to avoid unintended forks during upgrade periods. Equally, a spork can also be used to disable a feature if a vulnerability is discovered. New features or versions of Solaris go through rigorous testing before its release to the main network. When new features, patches or upgrades are to be released on the main network, a message is sent to all nodes informing them of the change and requesting them to update their clients. When the new code is run on a client, it is not activated until a predetermined percentage of nodes are running the new code. This percentage is set at 70% for Solaris. If an error occurs with the new code, the nodes blocks are not rejected, thus avoiding unintentional forks. Once that percentage consensus is reached and no errors are found, the new code is activated remotely by multiple members of the development team by signing a network message with their respective private keys. Code may also be deactivated by the same method.",
    "url": "http://localhost:4000/just-the-docs/writing/Solaris/",
    "relUrl": "/writing/Solaris/"
  },
  "22": {
    "id": "22",
    "title": "Work",
    "content": "Recent Roles Menlo One Company Role Description Menlo One Chief Operating Officer Working with the Founder/CEO, CGO, CTO and their respective teams, I worked on the design an implementation of business strategies relating to sales and product development, established policies to promote team culture the founders‚Äô vision as well as daily oversight of company operations. Dev 200 Company Role Description Dev 200 Operations Director As Operations Director of Dev200, I managed all large projects as well as the financial element of the business. Arcadia Group Company Role Description The Arcadia Group Advisor / Technical Writer I worked with Arcadia Media Group, and still do on occasion to assist with whitepaper composition, marketing strategy and growth hacking for businesses in the cryptocurrency and blockchain space. HS Ocean Group Company Role Description HS Ocean Group VP / Director : Offshore Services Overseeing global growth and service delivery for a multinational oil and gas services company, I managed offices and sites on three continents as well as oversaw the planning and commercial aspects of each branch.",
    "url": "http://localhost:4000/just-the-docs/Work/",
    "relUrl": "/Work/"
  },
  "23": {
    "id": "23",
    "title": "Writing",
    "content": "Writing Examples",
    "url": "http://localhost:4000/just-the-docs/writing",
    "relUrl": "/writing"
  },
  "24": {
    "id": "24",
    "title": "",
    "content": "Welcome to another page tits back",
    "url": "http://localhost:4000/just-the-docs/another-page/",
    "relUrl": "/another-page/"
  },
  "25": {
    "id": "25",
    "title": "ImTwitter Setup",
    "content": "Incomplete Post Chrome Extension Twitter HTML JavaScript Last updated on April 23, 2019 Introduction ImTwitter Chrome Extension This project is a Chrome extension that I built to automate a Twitter account from your browser. It is built with features to control the rate of which you perform tasks and has a built in hard limit per session that reduces the likelihood of a twitter soft ban. Features Auto Like Auto Un Like Auto Retweet Auto Un Retweet Auto Follow Auto UnFollow App Scheduling",
    "url": "http://localhost:4000/just-the-docs/ImTwitter/imtwitter%20setup/",
    "relUrl": "/ImTwitter/imtwitter%20setup/"
  },
  "26": {
    "id": "26",
    "title": "Home",
    "content": "About Me I am an Operations Expert / Product Owner / Growth Hacker working with multiple startups. I‚Äôm passionate about working with startups who focus on emerging technologies, as startups tend to be the best environments for idea generation and execution due to their inherently nimble nature. Specializing in Operations Management and Setup, Protocol Development, Product Design and Development, Growth Hacking, Project Management, I am a genralist at heart and love diversifying my skill set. I have sucessfully worked with teams in the Cryptocurrency, Commodities, Construction, Software, Finance, Cannabis and Music industries, with companies such as the World Health Organization, The Hemp Coin, Solaris, Bitcoin Foundation, Menlo One, RealFevr, PIMeo, BeatzCoin and many others.",
    "url": "http://localhost:4000/just-the-docs/",
    "relUrl": "/"
  }
  
}
